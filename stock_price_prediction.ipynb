{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple's Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAPL -- Apple's ticker\n",
    "apple = yf.Ticker('AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = apple.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.100266</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.088495</td>\n",
       "      <td>0.088495</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>116.970001</td>\n",
       "      <td>120.970001</td>\n",
       "      <td>116.809998</td>\n",
       "      <td>119.050003</td>\n",
       "      <td>169410200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>121.010002</td>\n",
       "      <td>123.470001</td>\n",
       "      <td>120.010002</td>\n",
       "      <td>122.720001</td>\n",
       "      <td>128166800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>122.019997</td>\n",
       "      <td>123.370003</td>\n",
       "      <td>120.889999</td>\n",
       "      <td>123.080002</td>\n",
       "      <td>89004200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>123.519997</td>\n",
       "      <td>123.779999</td>\n",
       "      <td>122.209999</td>\n",
       "      <td>122.940002</td>\n",
       "      <td>78967600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>122.599998</td>\n",
       "      <td>122.860001</td>\n",
       "      <td>121.519997</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>78133200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10081 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume  \\\n",
       "Date                                                                    \n",
       "1980-12-12    0.100266    0.100702    0.100266    0.100266  469033600   \n",
       "1980-12-15    0.095470    0.095470    0.095035    0.095035  175884800   \n",
       "1980-12-16    0.088495    0.088495    0.088059    0.088059  105728000   \n",
       "1980-12-17    0.090239    0.090675    0.090239    0.090239   86441600   \n",
       "1980-12-18    0.092855    0.093291    0.092855    0.092855   73449600   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2020-11-30  116.970001  120.970001  116.809998  119.050003  169410200   \n",
       "2020-12-01  121.010002  123.470001  120.010002  122.720001  128166800   \n",
       "2020-12-02  122.019997  123.370003  120.889999  123.080002   89004200   \n",
       "2020-12-03  123.519997  123.779999  122.209999  122.940002   78967600   \n",
       "2020-12-04  122.599998  122.860001  121.519997  122.250000   78133200   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "1980-12-12        0.0           0.0  \n",
       "1980-12-15        0.0           0.0  \n",
       "1980-12-16        0.0           0.0  \n",
       "1980-12-17        0.0           0.0  \n",
       "1980-12-18        0.0           0.0  \n",
       "...               ...           ...  \n",
       "2020-11-30        0.0           0.0  \n",
       "2020-12-01        0.0           0.0  \n",
       "2020-12-02        0.0           0.0  \n",
       "2020-12-03        0.0           0.0  \n",
       "2020-12-04        0.0           0.0  \n",
       "\n",
       "[10081 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that uses TimeseriesGenerator class to generate the training set with dividends info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(data, value_num):\n",
    "    close = data['Close']\n",
    "    dividends = data['Dividends']\n",
    "    tsg = TimeseriesGenerator(close, close,\n",
    "                              length=value_num,\n",
    "                              batch_size=len(close))\n",
    "    global_index = value_num\n",
    "    i, t = tsg[0]\n",
    "    has_dividends = np.zeros(len(i))\n",
    "    for b_row in range(len(t)):\n",
    "        assert(abs(t[b_row] - close[global_index]) <= 0.001)\n",
    "        has_dividends[b_row] = dividends[global_index] > 0            \n",
    "        global_index += 1\n",
    "    return np.concatenate((i, np.transpose([has_dividends])),\n",
    "                           axis=1), t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = history.min()\n",
    "normalized_h = (history - h_min) / (history.max() - h_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates a neural network with a specified number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(n+1,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_inputs(data, start, end, epochs):\n",
    "    models = {}\n",
    "    for inputs in range(start, end+1):\n",
    "        print('Using {} inputs'.format(inputs))\n",
    "        model_inputs, targets = generate_series(data, inputs)\n",
    "        \n",
    "        train_inputs = model_inputs[:-1000]\n",
    "        val_inputs = model_inputs[-1000:]\n",
    "        train_targets = targets[:-1000]\n",
    "        val_targets = targets[-1000:]\n",
    "        \n",
    "        m = create_model(inputs)\n",
    "        print('Training')\n",
    "        m.compile(optimizer='adam', loss='mse') \n",
    "        h = m.fit(train_inputs, train_targets,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(val_inputs, val_targets))\n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[inputs] = model_info\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.1161e-04 - val_loss: 0.0049\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.9060e-06 - val_loss: 0.0049\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.6361e-06 - val_loss: 0.0043\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9512e-05 - val_loss: 0.0038\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.6903e-06 - val_loss: 0.0040\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 1.7797e-06 - val_loss: 0.0040\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.8987e-06 - val_loss: 0.0042\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 1.8144e-06 - val_loss: 0.0043\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9398e-06 - val_loss: 0.0040\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.0000e-06 - val_loss: 0.0046\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.4308e-06 - val_loss: 0.0038\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.2007e-06 - val_loss: 0.0035\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.0884e-06 - val_loss: 0.0039\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.1471e-06 - val_loss: 0.0035\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0075e-06 - val_loss: 0.0041\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.3246e-06 - val_loss: 0.0023\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.2713e-06 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5871e-06 - val_loss: 0.0031\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3210e-06 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2704e-06 - val_loss: 0.0023\n",
      "Using 3 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 5.5093e-05 - val_loss: 0.0024\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.1630e-06 - val_loss: 0.0023\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2468e-06 - val_loss: 0.0026\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.9323e-06 - val_loss: 0.0029\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.3702e-06 - val_loss: 0.0031\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.1013e-06 - val_loss: 0.0031\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.1336e-06 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 6.1927e-06 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6861e-06 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8437e-06 - val_loss: 0.0028\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.2416e-06 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.3899e-06 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.9437e-06 - val_loss: 0.0026\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1807e-06 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2444e-06 - val_loss: 0.0022\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5227e-06 - val_loss: 0.0025\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.8915e-06 - val_loss: 0.0022\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9514e-06 - val_loss: 0.0022\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.1122e-06 - val_loss: 0.0018\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.4671e-06 - val_loss: 0.0022\n",
      "Using 4 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.2465e-04 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.7530e-05 - val_loss: 0.0036\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9893e-06 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2698e-06 - val_loss: 0.0032\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.0196e-06 - val_loss: 0.0027\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.6336e-06 - val_loss: 0.0038\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.2474e-06 - val_loss: 0.0030\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.4919e-06 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 7.0505e-06 - val_loss: 0.0027\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.7400e-06 - val_loss: 0.0028\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2554e-06 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.4969e-06 - val_loss: 0.0028\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2266e-06 - val_loss: 0.0026\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.3297e-06 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7813e-06 - val_loss: 0.0024\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0315e-06 - val_loss: 0.0019\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.7708e-06 - val_loss: 0.0019\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.7977e-06 - val_loss: 0.0018\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.8889e-06 - val_loss: 0.0015\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0179e-06 - val_loss: 0.0016\n",
      "Using 5 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.4287e-05 - val_loss: 2.7963e-04\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.5506e-06 - val_loss: 2.3003e-04\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 4.3219e-06 - val_loss: 1.7425e-04\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.4075e-06 - val_loss: 1.5774e-04\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 8.3465e-06 - val_loss: 2.6521e-04\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9798e-06 - val_loss: 1.6933e-04\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6979e-06 - val_loss: 2.5886e-04\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.4623e-06 - val_loss: 1.6425e-04\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 5.9563e-06 - val_loss: 1.5578e-04\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.7396e-06 - val_loss: 1.3943e-04\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.3473e-06 - val_loss: 2.4797e-04\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5200e-06 - val_loss: 1.6880e-04\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.5067e-06 - val_loss: 1.6437e-04\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.2625e-06 - val_loss: 4.5151e-04\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 6.5060e-06 - val_loss: 2.3329e-04\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7420e-06 - val_loss: 1.6690e-04\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 2.3863e-06 - val_loss: 1.4999e-04\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.8574e-06 - val_loss: 2.0264e-04\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.8553e-06 - val_loss: 1.5244e-04\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0413e-06 - val_loss: 1.9924e-04\n",
      "Using 6 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 2s 7ms/step - loss: 1.3907e-04 - val_loss: 0.0021\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.2899e-06 - val_loss: 0.0017\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.7221e-06 - val_loss: 0.0021\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.8072e-06 - val_loss: 0.0019\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1980e-06 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 8.5361e-06 - val_loss: 0.0021\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 3.3788e-06 - val_loss: 0.0018\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7393e-06 - val_loss: 0.0020\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.9707e-06 - val_loss: 0.0021\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 1.3736e-05 - val_loss: 0.0018\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1816e-06 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6361e-06 - val_loss: 0.0015\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.6563e-06 - val_loss: 0.0021\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.6440e-06 - val_loss: 0.0016\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.4576e-06 - val_loss: 0.0017\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5629e-06 - val_loss: 0.0018\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7119e-06 - val_loss: 0.0018\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 2s 8ms/step - loss: 3.3299e-06 - val_loss: 0.0022\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.4388e-06 - val_loss: 0.0016\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5063e-06 - val_loss: 0.0015\n",
      "Using 7 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.6136e-04 - val_loss: 0.0044\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.3381e-06 - val_loss: 0.0042\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 5.5998e-06 - val_loss: 0.0041\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.7707e-06 - val_loss: 0.0041\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.4891e-05 - val_loss: 0.0040\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.4753e-06 - val_loss: 0.0038\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.5708e-06 - val_loss: 0.0033\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.6720e-06 - val_loss: 0.0039\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8239e-06 - val_loss: 0.0034\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.5229e-06 - val_loss: 0.0040\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 6.0822e-06 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.8912e-06 - val_loss: 0.0028\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6059e-06 - val_loss: 0.0025\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.4520e-06 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6051e-06 - val_loss: 0.0026\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9881e-06 - val_loss: 0.0018\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.6811e-06 - val_loss: 0.0025\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.2334e-06 - val_loss: 0.0023\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.9108e-06 - val_loss: 0.0019\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 7.4163e-06 - val_loss: 9.8083e-04\n",
      "Using 8 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 8.8224e-05 - val_loss: 7.1695e-04\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.4693e-06 - val_loss: 6.6827e-04\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 7.4327e-06 - val_loss: 4.2859e-04\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.8584e-06 - val_loss: 5.3066e-04\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.9089e-06 - val_loss: 5.8770e-04\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 6.7730e-06 - val_loss: 4.8505e-04\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.5803e-06 - val_loss: 5.7473e-04\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.6324e-06 - val_loss: 4.7193e-04\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9239e-06 - val_loss: 6.9941e-04\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.0486e-06 - val_loss: 4.3284e-04\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.4412e-06 - val_loss: 4.0660e-04\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.3772e-06 - val_loss: 5.7989e-04\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7893e-06 - val_loss: 4.4929e-04\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.1556e-06 - val_loss: 4.0424e-04\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.2051e-06 - val_loss: 4.8805e-04\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.5986e-06 - val_loss: 2.9985e-04\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3060e-06 - val_loss: 4.3077e-04\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1977e-06 - val_loss: 2.2390e-04\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.3058e-06 - val_loss: 4.8539e-04\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8545e-06 - val_loss: 7.9143e-04\n",
      "Using 9 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 1.0096e-04 - val_loss: 9.8688e-04\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.0530e-06 - val_loss: 0.0010\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.8392e-06 - val_loss: 0.0015\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.9530e-06 - val_loss: 0.0012\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.8017e-06 - val_loss: 0.0013\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.2323e-06 - val_loss: 9.6372e-04\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.1837e-05 - val_loss: 0.0010\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 2.4040e-06 - val_loss: 0.0011\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.4837e-06 - val_loss: 0.0017\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.9746e-06 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.3132e-06 - val_loss: 0.0011\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 9.3901e-06 - val_loss: 8.5302e-04\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.5703e-06 - val_loss: 9.1464e-04\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8924e-06 - val_loss: 0.0011\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9192e-06 - val_loss: 9.1132e-04\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.6927e-06 - val_loss: 6.5973e-04\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.2276e-06 - val_loss: 0.0010\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7877e-06 - val_loss: 7.0966e-04\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1191e-06 - val_loss: 5.7492e-04\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.3827e-06 - val_loss: 6.4151e-04\n",
      "Using 10 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 8.6916e-05 - val_loss: 5.7133e-04\n",
      "Epoch 2/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 8.8222e-06 - val_loss: 4.7288e-04\n",
      "Epoch 3/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.2017e-06 - val_loss: 5.4722e-04\n",
      "Epoch 4/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.1618e-06 - val_loss: 3.3000e-04\n",
      "Epoch 5/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.2771e-06 - val_loss: 6.2028e-04\n",
      "Epoch 6/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 5.2126e-06 - val_loss: 3.3390e-04\n",
      "Epoch 7/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 7.1493e-06 - val_loss: 3.7973e-04\n",
      "Epoch 8/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.4057e-06 - val_loss: 2.5144e-04\n",
      "Epoch 9/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7325e-06 - val_loss: 3.6639e-04\n",
      "Epoch 10/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.6256e-06 - val_loss: 5.8513e-04\n",
      "Epoch 11/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.0292e-06 - val_loss: 3.7325e-04\n",
      "Epoch 12/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.2290e-06 - val_loss: 8.9902e-04\n",
      "Epoch 13/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8186e-06 - val_loss: 7.8666e-04\n",
      "Epoch 14/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8447e-06 - val_loss: 4.5567e-04\n",
      "Epoch 15/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.7370e-06 - val_loss: 5.7129e-04\n",
      "Epoch 16/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8880e-06 - val_loss: 0.0011\n",
      "Epoch 17/20\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.0342e-06 - val_loss: 4.8947e-04\n",
      "Epoch 18/20\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.8320e-06 - val_loss: 7.2359e-04\n",
      "Epoch 19/20\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 2.9600e-06 - val_loss: 5.9449e-04\n",
      "Epoch 20/20\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.8037e-06 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "trained_models = select_inputs(normalized_h, 2, 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "for k, v in trained_models.items():\n",
    "    train_history = v['history']\n",
    "    loss = train_history['loss'][-1]\n",
    "    val_loss = train_history['val_loss'][-1]\n",
    "    model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'inputs': 2,\n",
       "  'loss': 2.270406639581779e-06,\n",
       "  'val_loss': 0.0023233152460306883},\n",
       " 3: {'inputs': 3,\n",
       "  'loss': 2.4671135179232806e-06,\n",
       "  'val_loss': 0.002182313008233905},\n",
       " 4: {'inputs': 4,\n",
       "  'loss': 2.0179443254164653e-06,\n",
       "  'val_loss': 0.0016149987932294607},\n",
       " 5: {'inputs': 5,\n",
       "  'loss': 2.0412910544109764e-06,\n",
       "  'val_loss': 0.00019924395019188523},\n",
       " 6: {'inputs': 6,\n",
       "  'loss': 2.506265673218877e-06,\n",
       "  'val_loss': 0.001483036670833826},\n",
       " 7: {'inputs': 7,\n",
       "  'loss': 7.416348580591148e-06,\n",
       "  'val_loss': 0.0009808323811739683},\n",
       " 8: {'inputs': 8,\n",
       "  'loss': 2.8544934593810467e-06,\n",
       "  'val_loss': 0.0007914252346381545},\n",
       " 9: {'inputs': 9,\n",
       "  'loss': 2.3827169570722617e-06,\n",
       "  'val_loss': 0.0006415134994313121},\n",
       " 10: {'inputs': 10,\n",
       "  'loss': 2.8036899948347127e-06,\n",
       "  'val_loss': 0.001745950779877603}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e92c86250>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.3494789556915936\n",
      "3 0.3305972704864117\n",
      "4 0.254627920017116\n",
      "5 0.06504343049664488\n",
      "6 0.23695680150853507\n",
      "7 0.16970635602471343\n",
      "8 0.14434274355740417\n",
      "9 0.12426798278078649\n",
      "10 0.2721637707065709\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "close_min = history['Close'].min()\n",
    "close_max = history['Close'].max()\n",
    "for k in model_stats:\n",
    "    e = ((close_max - close_min) * model_stats[k]['val_loss'] + close_min)\n",
    "    vals.append(e)\n",
    "    print(k, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
