{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STONKS\n",
    "Predicting stock price using TimeSeriesGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple's Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAPL -- Apple's ticker\n",
    "apple = yf.Ticker('AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = apple.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.100266</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.095470</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.088495</td>\n",
       "      <td>0.088495</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>122.019997</td>\n",
       "      <td>123.370003</td>\n",
       "      <td>120.889999</td>\n",
       "      <td>123.080002</td>\n",
       "      <td>89004200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>123.519997</td>\n",
       "      <td>123.779999</td>\n",
       "      <td>122.209999</td>\n",
       "      <td>122.940002</td>\n",
       "      <td>78967600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>122.599998</td>\n",
       "      <td>122.860001</td>\n",
       "      <td>121.519997</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>78260400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>122.309998</td>\n",
       "      <td>124.570000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>123.750000</td>\n",
       "      <td>86561300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-08</th>\n",
       "      <td>122.309998</td>\n",
       "      <td>124.559998</td>\n",
       "      <td>123.769997</td>\n",
       "      <td>123.839996</td>\n",
       "      <td>6995120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10083 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume  \\\n",
       "Date                                                                    \n",
       "1980-12-12    0.100266    0.100702    0.100266    0.100266  469033600   \n",
       "1980-12-15    0.095470    0.095470    0.095035    0.095035  175884800   \n",
       "1980-12-16    0.088495    0.088495    0.088059    0.088059  105728000   \n",
       "1980-12-17    0.090239    0.090675    0.090239    0.090239   86441600   \n",
       "1980-12-18    0.092855    0.093291    0.092855    0.092855   73449600   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2020-12-02  122.019997  123.370003  120.889999  123.080002   89004200   \n",
       "2020-12-03  123.519997  123.779999  122.209999  122.940002   78967600   \n",
       "2020-12-04  122.599998  122.860001  121.519997  122.250000   78260400   \n",
       "2020-12-07  122.309998  124.570000  122.250000  123.750000   86561300   \n",
       "2020-12-08  122.309998  124.559998  123.769997  123.839996    6995120   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "1980-12-12        0.0           0.0  \n",
       "1980-12-15        0.0           0.0  \n",
       "1980-12-16        0.0           0.0  \n",
       "1980-12-17        0.0           0.0  \n",
       "1980-12-18        0.0           0.0  \n",
       "...               ...           ...  \n",
       "2020-12-02        0.0           0.0  \n",
       "2020-12-03        0.0           0.0  \n",
       "2020-12-04        0.0           0.0  \n",
       "2020-12-07        0.0           0.0  \n",
       "2020-12-08        0.0           0.0  \n",
       "\n",
       "[10083 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that uses TimeseriesGenerator class with information about dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(data, value_num):\n",
    "    close = data['Close']\n",
    "    dividends = data['Dividends']\n",
    "    tsg = TimeseriesGenerator(close, close,\n",
    "                              length=value_num,\n",
    "                              batch_size=len(close))\n",
    "    global_index = value_num\n",
    "    i, t = tsg[0]\n",
    "    has_dividends = np.zeros(len(i))\n",
    "    for b_row in range(len(t)):\n",
    "        assert(abs(t[b_row] - close[global_index]) <= 0.001)\n",
    "        has_dividends[b_row] = dividends[global_index] > 0            \n",
    "        global_index += 1\n",
    "    return np.concatenate((i, np.transpose([has_dividends])),\n",
    "                           axis=1), t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = history.min()\n",
    "normalized_h = (history - h_min) / (history.max() - h_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates a neural network with a specified number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(n+1,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_inputs(data, start, end, epochs):\n",
    "    models = {}\n",
    "    for inputs in range(start, end+1):\n",
    "        print('Using {} inputs'.format(inputs))\n",
    "        model_inputs, targets = generate_series(data, inputs)\n",
    "        \n",
    "        train_inputs = model_inputs[:-1000]\n",
    "        val_inputs = model_inputs[-1000:]\n",
    "        train_targets = targets[:-1000]\n",
    "        val_targets = targets[-1000:]\n",
    "        \n",
    "        m = create_model(inputs)\n",
    "        print('Training')\n",
    "        m.compile(optimizer='adam', loss='mse', metrics=['accuracy']) \n",
    "        h = m.fit(train_inputs, train_targets,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(val_inputs, val_targets))\n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[inputs] = model_info\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.2348e-04 - accuracy: 1.1012e-04 - val_loss: 0.0052 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.3216e-06 - accuracy: 1.1012e-04 - val_loss: 0.0047 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 1.5720e-06 - accuracy: 1.1012e-04 - val_loss: 0.0044 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9662e-06 - accuracy: 1.1012e-04 - val_loss: 0.0047 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0978e-06 - accuracy: 1.1012e-04 - val_loss: 0.0046 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.6039e-06 - accuracy: 1.1012e-04 - val_loss: 0.0044 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.9143e-06 - accuracy: 1.1012e-04 - val_loss: 0.0046 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 1.8960e-06 - accuracy: 1.1012e-04 - val_loss: 0.0047 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.7288e-06 - accuracy: 1.1012e-04 - val_loss: 0.0044 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.4786e-06 - accuracy: 1.1012e-04 - val_loss: 0.0048 - val_accuracy: 0.0010\n",
      "Using 3 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 3.9190e-05 - accuracy: 1.1013e-04 - val_loss: 2.1492e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.6077e-05 - accuracy: 1.1013e-04 - val_loss: 3.0178e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.1763e-06 - accuracy: 1.1013e-04 - val_loss: 2.1400e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.1464e-06 - accuracy: 1.1013e-04 - val_loss: 2.5667e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.1262e-06 - accuracy: 1.1013e-04 - val_loss: 2.9520e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 7.0586e-06 - accuracy: 1.1013e-04 - val_loss: 2.1538e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.7172e-06 - accuracy: 1.1013e-04 - val_loss: 3.5442e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.2055e-06 - accuracy: 1.1013e-04 - val_loss: 1.9961e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.0114e-06 - accuracy: 1.1013e-04 - val_loss: 2.1710e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7443e-06 - accuracy: 1.1013e-04 - val_loss: 2.7500e-04 - val_accuracy: 0.0010\n",
      "Using 4 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.9732e-05 - accuracy: 1.1014e-04 - val_loss: 1.7888e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3461e-06 - accuracy: 1.1014e-04 - val_loss: 3.3878e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 7.4769e-06 - accuracy: 1.1014e-04 - val_loss: 2.9105e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.3905e-06 - accuracy: 1.1014e-04 - val_loss: 5.0183e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 5.7959e-06 - accuracy: 1.1014e-04 - val_loss: 3.9722e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.2146e-06 - accuracy: 1.1014e-04 - val_loss: 2.3764e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.1581e-06 - accuracy: 1.1014e-04 - val_loss: 2.2456e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.1750e-05 - accuracy: 1.1014e-04 - val_loss: 2.5297e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.0546e-06 - accuracy: 1.1014e-04 - val_loss: 2.2297e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.1065e-06 - accuracy: 1.1014e-04 - val_loss: 3.0750e-04 - val_accuracy: 0.0010\n",
      "Using 5 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 3.9956e-05 - accuracy: 1.1016e-04 - val_loss: 2.2017e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 3.3719e-06 - accuracy: 1.1016e-04 - val_loss: 2.0038e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.5354e-06 - accuracy: 1.1016e-04 - val_loss: 1.9693e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 7.6226e-06 - accuracy: 1.1016e-04 - val_loss: 5.9240e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.0535e-06 - accuracy: 1.1016e-04 - val_loss: 2.9521e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 6.1052e-06 - accuracy: 1.1016e-04 - val_loss: 2.6785e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 4.4377e-06 - accuracy: 1.1016e-04 - val_loss: 2.7221e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.3498e-06 - accuracy: 1.1016e-04 - val_loss: 1.7124e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.4108e-06 - accuracy: 1.1016e-04 - val_loss: 2.6899e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 7.2458e-06 - accuracy: 1.1016e-04 - val_loss: 3.9000e-04 - val_accuracy: 0.0010\n",
      "Using 6 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 3.4592e-05 - accuracy: 1.1017e-04 - val_loss: 3.8021e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.7391e-06 - accuracy: 1.1017e-04 - val_loss: 3.0430e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.5200e-06 - accuracy: 1.1017e-04 - val_loss: 3.4783e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9430e-06 - accuracy: 1.1017e-04 - val_loss: 2.2511e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.3041e-06 - accuracy: 1.1017e-04 - val_loss: 1.8808e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.6904e-06 - accuracy: 1.1017e-04 - val_loss: 3.8960e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.7152e-06 - accuracy: 1.1017e-04 - val_loss: 2.0397e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9414e-06 - accuracy: 1.1017e-04 - val_loss: 1.7821e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7693e-06 - accuracy: 1.1017e-04 - val_loss: 1.8042e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.5122e-06 - accuracy: 1.1017e-04 - val_loss: 3.1675e-04 - val_accuracy: 0.0010\n",
      "Using 7 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.5626e-05 - accuracy: 1.1018e-04 - val_loss: 3.5212e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 4.6228e-06 - accuracy: 1.1018e-04 - val_loss: 2.7878e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 5.3947e-06 - accuracy: 1.1018e-04 - val_loss: 4.5121e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.5004e-06 - accuracy: 1.1018e-04 - val_loss: 2.6615e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 3.3762e-06 - accuracy: 1.1018e-04 - val_loss: 2.9796e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3149e-06 - accuracy: 1.1018e-04 - val_loss: 2.3013e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 4.9334e-06 - accuracy: 1.1018e-04 - val_loss: 2.2352e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.9357e-06 - accuracy: 1.1018e-04 - val_loss: 2.5616e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.3033e-06 - accuracy: 1.1018e-04 - val_loss: 2.9157e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.9435e-06 - accuracy: 1.1018e-04 - val_loss: 3.0298e-04 - val_accuracy: 0.0010\n",
      "Using 8 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 1.3262e-04 - accuracy: 1.1019e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.5585e-06 - accuracy: 1.1019e-04 - val_loss: 0.0012 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.2180e-06 - accuracy: 1.1019e-04 - val_loss: 4.4489e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.0991e-06 - accuracy: 1.1019e-04 - val_loss: 6.9507e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3475e-06 - accuracy: 1.1019e-04 - val_loss: 4.7597e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9205e-06 - accuracy: 1.1019e-04 - val_loss: 3.1182e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 4.9508e-06 - accuracy: 1.1019e-04 - val_loss: 5.1450e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 7.2130e-06 - accuracy: 1.1019e-04 - val_loss: 4.4959e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 2.5953e-06 - accuracy: 1.1019e-04 - val_loss: 7.9878e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.9877e-06 - accuracy: 1.1019e-04 - val_loss: 7.0424e-04 - val_accuracy: 0.0010\n",
      "Using 9 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 9.7371e-05 - accuracy: 1.1020e-04 - val_loss: 2.5896e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.4539e-06 - accuracy: 1.1020e-04 - val_loss: 1.8180e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 3.1192e-06 - accuracy: 1.1020e-04 - val_loss: 2.1456e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 4.8169e-06 - accuracy: 1.1020e-04 - val_loss: 2.7817e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 5ms/step - loss: 2.1841e-06 - accuracy: 1.1020e-04 - val_loss: 3.1664e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.3588e-06 - accuracy: 1.1020e-04 - val_loss: 3.5665e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.0172e-06 - accuracy: 1.1020e-04 - val_loss: 3.8639e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 2.6044e-06 - accuracy: 1.1020e-04 - val_loss: 5.3571e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.3805e-06 - accuracy: 1.1020e-04 - val_loss: 6.8004e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 2.7024e-06 - accuracy: 1.1020e-04 - val_loss: 6.3743e-04 - val_accuracy: 0.0010\n",
      "Using 10 inputs\n",
      "Training\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 3.9670e-05 - accuracy: 1.1022e-04 - val_loss: 3.6182e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.8984e-06 - accuracy: 1.1022e-04 - val_loss: 3.3868e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 5.3189e-06 - accuracy: 1.1022e-04 - val_loss: 2.7299e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.7534e-06 - accuracy: 1.1022e-04 - val_loss: 2.4714e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 5.0749e-06 - accuracy: 1.1022e-04 - val_loss: 2.2106e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 2s 5ms/step - loss: 4.3288e-06 - accuracy: 1.1022e-04 - val_loss: 2.4330e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 2s 6ms/step - loss: 4.9966e-06 - accuracy: 1.1022e-04 - val_loss: 3.5454e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 1.1137e-05 - accuracy: 1.1022e-04 - val_loss: 2.8160e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.2184e-06 - accuracy: 1.1022e-04 - val_loss: 2.0309e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 1s 3ms/step - loss: 3.6534e-06 - accuracy: 1.1022e-04 - val_loss: 1.8671e-04 - val_accuracy: 0.0010\n"
     ]
    }
   ],
   "source": [
    "trained_models = select_inputs(normalized_h, 2, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "for k, v in trained_models.items():\n",
    "    train_history = v['history']\n",
    "    loss = train_history['loss'][-1]\n",
    "    val_loss = train_history['val_loss'][-1]\n",
    "    accuracy = train_history['accuracy'][-1]\n",
    "    model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'inputs': 2,\n",
       "  'loss': 2.4785881578281987e-06,\n",
       "  'val_loss': 0.004786770325154066,\n",
       "  'accuracy': 0.00011012003233190626},\n",
       " 3: {'inputs': 3,\n",
       "  'loss': 2.7443195449450286e-06,\n",
       "  'val_loss': 0.00027500325813889503,\n",
       "  'accuracy': 0.0001101321613532491},\n",
       " 4: {'inputs': 4,\n",
       "  'loss': 2.106454985550954e-06,\n",
       "  'val_loss': 0.000307499518385157,\n",
       "  'accuracy': 0.00011014429037459195},\n",
       " 5: {'inputs': 5,\n",
       "  'loss': 7.245840606628917e-06,\n",
       "  'val_loss': 0.00039000165998004377,\n",
       "  'accuracy': 0.00011015641939593479},\n",
       " 6: {'inputs': 6,\n",
       "  'loss': 2.512232640583534e-06,\n",
       "  'val_loss': 0.00031674656202085316,\n",
       "  'accuracy': 0.00011016855569323525},\n",
       " 7: {'inputs': 7,\n",
       "  'loss': 3.943517640436767e-06,\n",
       "  'val_loss': 0.00030297672492451966,\n",
       "  'accuracy': 0.00011018069926649332},\n",
       " 8: {'inputs': 8,\n",
       "  'loss': 2.9877267024858156e-06,\n",
       "  'val_loss': 0.0007042440702207386,\n",
       "  'accuracy': 0.00011019283556379378},\n",
       " 9: {'inputs': 9,\n",
       "  'loss': 2.7024086648452794e-06,\n",
       "  'val_loss': 0.0006374309887178242,\n",
       "  'accuracy': 0.00011020497913705185},\n",
       " 10: {'inputs': 10,\n",
       "  'loss': 3.653373596534948e-06,\n",
       "  'val_loss': 0.0001867119426606223,\n",
       "  'accuracy': 0.00011021712998626754}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e180a0e50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.6793615451307186\n",
      "3 0.07518840001180607\n",
      "4 0.0795399916312235\n",
      "5 0.09058789761263861\n",
      "6 0.0807782681985744\n",
      "7 0.07893434193582725\n",
      "8 0.1326682671230422\n",
      "9 0.1237212915839421\n",
      "10 0.06336526265412235\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "close_min = history['Close'].min()\n",
    "close_max = history['Close'].max()\n",
    "for k in model_stats:\n",
    "    e = ((close_max - close_min) * model_stats[k]['val_loss'] + close_min)\n",
    "    vals.append(e)\n",
    "    print(k, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
