{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAZON STOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazons's Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMZN -- Amazon's ticker\n",
    "amazon = yf.Ticker('AMZN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = amazon.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-15</th>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.927083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>72156000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-16</th>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>14700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-19</th>\n",
       "      <td>1.760417</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>6106800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-20</th>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>5467200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-21</th>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>18853200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>3208.479980</td>\n",
       "      <td>3228.389893</td>\n",
       "      <td>3125.550049</td>\n",
       "      <td>3168.040039</td>\n",
       "      <td>4063900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>3188.500000</td>\n",
       "      <td>3248.949951</td>\n",
       "      <td>3157.179932</td>\n",
       "      <td>3220.080078</td>\n",
       "      <td>4544400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>3221.649902</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3173.260010</td>\n",
       "      <td>3203.530029</td>\n",
       "      <td>3129300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>3205.459961</td>\n",
       "      <td>3228.639893</td>\n",
       "      <td>3181.310059</td>\n",
       "      <td>3186.729980</td>\n",
       "      <td>2892000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>3198.209961</td>\n",
       "      <td>3198.209961</td>\n",
       "      <td>3158.760010</td>\n",
       "      <td>3162.580078</td>\n",
       "      <td>2903800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5930 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Volume  \\\n",
       "Date                                                                       \n",
       "1997-05-15     2.437500     2.500000     1.927083     1.958333  72156000   \n",
       "1997-05-16     1.968750     1.979167     1.708333     1.729167  14700000   \n",
       "1997-05-19     1.760417     1.770833     1.625000     1.708333   6106800   \n",
       "1997-05-20     1.729167     1.750000     1.635417     1.635417   5467200   \n",
       "1997-05-21     1.635417     1.645833     1.375000     1.427083  18853200   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "2020-11-30  3208.479980  3228.389893  3125.550049  3168.040039   4063900   \n",
       "2020-12-01  3188.500000  3248.949951  3157.179932  3220.080078   4544400   \n",
       "2020-12-02  3221.649902  3232.000000  3173.260010  3203.530029   3129300   \n",
       "2020-12-03  3205.459961  3228.639893  3181.310059  3186.729980   2892000   \n",
       "2020-12-04  3198.209961  3198.209961  3158.760010  3162.580078   2903800   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "1997-05-15          0           0.0  \n",
       "1997-05-16          0           0.0  \n",
       "1997-05-19          0           0.0  \n",
       "1997-05-20          0           0.0  \n",
       "1997-05-21          0           0.0  \n",
       "...               ...           ...  \n",
       "2020-11-30          0           0.0  \n",
       "2020-12-01          0           0.0  \n",
       "2020-12-02          0           0.0  \n",
       "2020-12-03          0           0.0  \n",
       "2020-12-04          0           0.0  \n",
       "\n",
       "[5930 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that uses TimeseriesGenerator class to generate the training set with dividends info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(data, value_num):\n",
    "    close = data['Close']\n",
    "    dividends = data['Dividends']\n",
    "    tsg = TimeseriesGenerator(close, close,\n",
    "                              length=value_num,\n",
    "                              batch_size=len(close))\n",
    "    global_index = value_num\n",
    "    i, t = tsg[0]\n",
    "    has_dividends = np.zeros(len(i))\n",
    "    for b_row in range(len(t)):\n",
    "        assert(abs(t[b_row] - close[global_index]) <= 0.001)\n",
    "        has_dividends[b_row] = dividends[global_index] > 0            \n",
    "        global_index += 1\n",
    "    return np.concatenate((i, np.transpose([has_dividends])),\n",
    "                           axis=1), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(history, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = history.min()\n",
    "normalized_h = (history - h_min) / (history.max() - h_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(normalized_h, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates a neural network with a specified number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(n+1,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs[:-1000]\n",
    "val_inputs = inputs[-1000:]\n",
    "train_targets = targets[:-1000]\n",
    "val_targets = targets[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_inputs(data, start, end, epochs):\n",
    "    models = {}\n",
    "    for inputs in range(start, end+1):\n",
    "#         print('Using {} inputs'.format(inputs))\n",
    "        model_inputs, targets = generate_series(data, inputs)\n",
    "        \n",
    "        train_inputs = model_inputs[:-1000]\n",
    "        val_inputs = model_inputs[-1000:]\n",
    "        train_targets = targets[:-1000]\n",
    "        val_targets = targets[-1000:]\n",
    "        \n",
    "        m = create_model(inputs)\n",
    "#         print('Training')\n",
    "        m.compile(optimizer='adam', loss='mse') \n",
    "        h = m.fit(train_inputs, train_targets,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(val_inputs, val_targets))\n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[inputs] = model_info\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2330e-04 - val_loss: 0.0040\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.3024e-06 - val_loss: 0.0033\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.2383e-06 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.2004e-06 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.3766e-06 - val_loss: 0.0032\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.4040e-06 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.6072e-06 - val_loss: 0.0033\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.3990e-06 - val_loss: 0.0036\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.4487e-06 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.6707e-06 - val_loss: 0.0032\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2941e-06 - val_loss: 0.0034\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.3418e-06 - val_loss: 0.0030\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.2656e-06 - val_loss: 0.0030\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.5083e-06 - val_loss: 0.0033\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.5158e-06 - val_loss: 0.0031\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.6140e-06 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.6303e-06 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.8508e-06 - val_loss: 0.0031\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 2.5593e-06 - val_loss: 0.0033\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 2.7858e-06 - val_loss: 0.0025\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 2.1885e-04 - val_loss: 0.0050\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 3.5307e-06 - val_loss: 0.0047\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6142e-06 - val_loss: 0.0043\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.3862e-06 - val_loss: 0.0041\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.4702e-06 - val_loss: 0.0038\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3091e-06 - val_loss: 0.0041\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3688e-06 - val_loss: 0.0037\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.2450e-06 - val_loss: 0.0037\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3381e-06 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.0526e-06 - val_loss: 0.0037\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.9412e-06 - val_loss: 0.0030\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.2428e-06 - val_loss: 0.0034\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.8231e-06 - val_loss: 0.0034\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.1932e-06 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.0937e-06 - val_loss: 0.0035\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.9157e-06 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.7017e-06 - val_loss: 0.0032\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.7448e-06 - val_loss: 0.0025\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.8148e-06 - val_loss: 0.0035\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.9781e-06 - val_loss: 0.0028\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 9.9931e-05 - val_loss: 9.2759e-04\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.0609e-06 - val_loss: 0.0010\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.3655e-06 - val_loss: 5.1869e-04\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.0331e-06 - val_loss: 4.7659e-04\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.7380e-06 - val_loss: 5.8873e-04\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 3.8554e-06 - val_loss: 8.6109e-04\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.7332e-06 - val_loss: 3.9959e-04\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6030e-06 - val_loss: 7.0305e-04\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.1212e-06 - val_loss: 7.8259e-04\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 4.1201e-06 - val_loss: 5.5218e-04\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 3.4596e-06 - val_loss: 9.6595e-04\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.3845e-06 - val_loss: 8.4887e-04\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 2.9723e-06 - val_loss: 0.0011\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.0652e-06 - val_loss: 0.0015\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.8232e-06 - val_loss: 0.0013\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6006e-06 - val_loss: 0.0012\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.5709e-06 - val_loss: 8.7979e-04\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.5834e-06 - val_loss: 0.0021\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8536e-06 - val_loss: 8.2806e-04\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.9612e-06 - val_loss: 9.6349e-04\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.8134e-04 - val_loss: 0.0026\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.8218e-06 - val_loss: 0.0031\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.5252e-06 - val_loss: 0.0035\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.6215e-06 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.2679e-06 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.2723e-06 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1427e-06 - val_loss: 0.0032\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.8921e-06 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.9557e-06 - val_loss: 0.0031\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.9500e-06 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.8912e-06 - val_loss: 0.0035\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1002e-06 - val_loss: 0.0031\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.1715e-06 - val_loss: 0.0031\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.0152e-06 - val_loss: 0.0038\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.6958e-06 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.0337e-06 - val_loss: 0.0032\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 2.8566e-06 - val_loss: 0.0033\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.6783e-06 - val_loss: 0.0029\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 2.8955e-06 - val_loss: 0.0033\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.8857e-06 - val_loss: 0.0028\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 2.0106e-05 - val_loss: 3.0481e-04\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 4.8797e-06 - val_loss: 2.9271e-04\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.5262e-06 - val_loss: 2.5692e-04\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.7467e-06 - val_loss: 2.8044e-04\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.9806e-06 - val_loss: 2.4505e-04\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.7402e-06 - val_loss: 3.4213e-04\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3950e-06 - val_loss: 1.8523e-04\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.9026e-06 - val_loss: 1.7553e-04\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.9078e-06 - val_loss: 1.5749e-04\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.2627e-06 - val_loss: 1.5244e-04\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.7314e-06 - val_loss: 2.7968e-04\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.0949e-06 - val_loss: 2.1941e-04\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1267e-06 - val_loss: 1.4134e-04\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.0875e-06 - val_loss: 1.6189e-04\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1191e-06 - val_loss: 2.1430e-04\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.3791e-06 - val_loss: 1.7505e-04\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.3160e-06 - val_loss: 2.2687e-04\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1044e-06 - val_loss: 1.3628e-04\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1509e-06 - val_loss: 1.3608e-04\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1848e-06 - val_loss: 1.8103e-04\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.4633e-04 - val_loss: 5.3399e-04\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 5.1321e-06 - val_loss: 5.2342e-04\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 5.0019e-06 - val_loss: 4.4820e-04\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.8123e-06 - val_loss: 5.2341e-04\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.8202e-06 - val_loss: 5.1833e-04\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 4.2589e-06 - val_loss: 5.7431e-04\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.9451e-06 - val_loss: 3.8635e-04\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.7071e-06 - val_loss: 3.3032e-04\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.0092e-06 - val_loss: 7.0641e-04\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.1013e-06 - val_loss: 3.3903e-04\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.7735e-06 - val_loss: 6.9852e-04\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.1836e-06 - val_loss: 4.1700e-04\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.3550e-06 - val_loss: 5.0082e-04\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.0408e-06 - val_loss: 6.4897e-04\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6572e-06 - val_loss: 6.4683e-04\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.2747e-06 - val_loss: 5.9354e-04\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.5888e-06 - val_loss: 2.2228e-04\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.6923e-06 - val_loss: 2.5701e-04\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.8261e-06 - val_loss: 3.7906e-04\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 2.9344e-06 - val_loss: 4.2817e-04\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 1.4104e-04 - val_loss: 7.4629e-04\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 5.4418e-06 - val_loss: 5.4049e-04\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.8918e-06 - val_loss: 5.1485e-04\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.3622e-06 - val_loss: 6.2164e-04\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.8357e-06 - val_loss: 5.2095e-04\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.7355e-06 - val_loss: 7.3141e-04\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.1980e-06 - val_loss: 5.2091e-04\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 4.1567e-06 - val_loss: 8.0532e-04\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.2293e-06 - val_loss: 7.7271e-04\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.3446e-06 - val_loss: 0.0011\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.9789e-06 - val_loss: 8.6262e-04\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.3524e-06 - val_loss: 6.3419e-04\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3365e-06 - val_loss: 5.7192e-04\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.3106e-06 - val_loss: 8.5687e-04\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.2596e-06 - val_loss: 5.5988e-04\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.3714e-06 - val_loss: 7.7505e-04\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 3.4245e-06 - val_loss: 5.2667e-04\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.1480e-06 - val_loss: 0.0011\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.3723e-06 - val_loss: 8.8200e-04\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.2031e-06 - val_loss: 0.0013\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.0244e-04 - val_loss: 0.0019\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 5.3162e-06 - val_loss: 0.0016\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.5120e-06 - val_loss: 0.0025\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.7494e-06 - val_loss: 0.0016\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 4.3033e-06 - val_loss: 0.0015\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.9151e-06 - val_loss: 0.0017\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 3.7479e-06 - val_loss: 0.0021\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.4309e-06 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.5548e-06 - val_loss: 0.0023\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 3.5882e-06 - val_loss: 0.0014\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.9343e-06 - val_loss: 0.0017\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.2554e-06 - val_loss: 0.0014\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.0465e-06 - val_loss: 0.0019\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 9ms/step - loss: 3.0840e-06 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 9ms/step - loss: 3.3793e-06 - val_loss: 0.0014\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 3.1634e-06 - val_loss: 0.0017\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.5269e-06 - val_loss: 0.0022\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.4104e-06 - val_loss: 0.0021\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.4250e-06 - val_loss: 0.0018\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.4698e-06 - val_loss: 0.0017\n",
      "Epoch 1/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 4.6828e-05 - val_loss: 4.0405e-04\n",
      "Epoch 2/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 6.6273e-06 - val_loss: 4.1642e-04\n",
      "Epoch 3/20\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 6.0405e-06 - val_loss: 3.2219e-04\n",
      "Epoch 4/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 5.3107e-06 - val_loss: 3.5525e-04\n",
      "Epoch 5/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 5.5753e-06 - val_loss: 3.6728e-04\n",
      "Epoch 6/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.8067e-06 - val_loss: 2.6847e-04\n",
      "Epoch 7/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.7741e-06 - val_loss: 3.5266e-04\n",
      "Epoch 8/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 4.7940e-06 - val_loss: 4.6194e-04\n",
      "Epoch 9/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 4.2309e-06 - val_loss: 3.8957e-04\n",
      "Epoch 10/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 4.2382e-06 - val_loss: 4.6120e-04\n",
      "Epoch 11/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.8735e-06 - val_loss: 2.3135e-04\n",
      "Epoch 12/20\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 3.7817e-06 - val_loss: 3.3311e-04\n",
      "Epoch 13/20\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 3.5919e-06 - val_loss: 3.0923e-04\n",
      "Epoch 14/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 5.0785e-06 - val_loss: 4.8309e-04\n",
      "Epoch 15/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6113e-06 - val_loss: 3.6896e-04\n",
      "Epoch 16/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.6366e-06 - val_loss: 2.2044e-04\n",
      "Epoch 17/20\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 4.8476e-06 - val_loss: 2.8839e-04\n",
      "Epoch 18/20\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 3.7297e-06 - val_loss: 5.7001e-04\n",
      "Epoch 19/20\n",
      "154/154 [==============================] - 1s 8ms/step - loss: 4.6762e-06 - val_loss: 5.5334e-04\n",
      "Epoch 20/20\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 3.2935e-06 - val_loss: 2.7884e-04\n"
     ]
    }
   ],
   "source": [
    "trained_models = select_inputs(normalized_h, 2, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trained_models[2]['model'].predict(val_targets))\n",
    "model = trained_models[2]['model']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "for k, v in trained_models.items():\n",
    "    train_history = v['history']\n",
    "    loss = train_history['loss'][-1]\n",
    "    val_loss = train_history['val_loss'][-1]\n",
    "    model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'inputs': 2,\n",
       "  'loss': 2.7858116027346114e-06,\n",
       "  'val_loss': 0.0025205567944794893},\n",
       " 3: {'inputs': 3,\n",
       "  'loss': 2.978063776026829e-06,\n",
       "  'val_loss': 0.0027541921008378267},\n",
       " 4: {'inputs': 4,\n",
       "  'loss': 2.9612326670758193e-06,\n",
       "  'val_loss': 0.0009634866146370769},\n",
       " 5: {'inputs': 5,\n",
       "  'loss': 2.8857186862296658e-06,\n",
       "  'val_loss': 0.0028152992017567158},\n",
       " 6: {'inputs': 6,\n",
       "  'loss': 3.1847675927565433e-06,\n",
       "  'val_loss': 0.0001810312387533486},\n",
       " 7: {'inputs': 7,\n",
       "  'loss': 2.934394842668553e-06,\n",
       "  'val_loss': 0.00042816679342649877},\n",
       " 8: {'inputs': 8,\n",
       "  'loss': 3.2030536658567144e-06,\n",
       "  'val_loss': 0.001275884686037898},\n",
       " 9: {'inputs': 9,\n",
       "  'loss': 3.469835064606741e-06,\n",
       "  'val_loss': 0.0017034143675118685},\n",
       " 10: {'inputs': 10,\n",
       "  'loss': 3.293498821221874e-06,\n",
       "  'val_loss': 0.0002788429846987128}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fce9faf58e0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10.293535264567842\n",
      "3 11.118280539841276\n",
      "4 4.796993264513407\n",
      "5 11.333991913066747\n",
      "6 2.03488344288124\n",
      "7 2.9072853253096858\n",
      "8 5.899775362854281\n",
      "9 7.408978275422682\n",
      "10 2.3801641994247635\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "close_min = history['Close'].min()\n",
    "close_max = history['Close'].max()\n",
    "for k in model_stats:\n",
    "    e = ((close_max - close_min) * model_stats[k]['val_loss'] + close_min)\n",
    "    vals.append(e)\n",
    "    print(k, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
