{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACEBOOK STOCKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceBook's Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB -- FaceBook's ticker\n",
    "facebook = yf.Ticker('FB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = facebook.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-05-18</th>\n",
       "      <td>42.049999</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.230000</td>\n",
       "      <td>573576400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-21</th>\n",
       "      <td>36.529999</td>\n",
       "      <td>36.660000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.029999</td>\n",
       "      <td>168192700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-22</th>\n",
       "      <td>32.610001</td>\n",
       "      <td>33.590000</td>\n",
       "      <td>30.940001</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>101786600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-23</th>\n",
       "      <td>31.370001</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>31.360001</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>73600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-24</th>\n",
       "      <td>32.950001</td>\n",
       "      <td>33.209999</td>\n",
       "      <td>31.770000</td>\n",
       "      <td>33.029999</td>\n",
       "      <td>50237200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>279.160004</td>\n",
       "      <td>289.299988</td>\n",
       "      <td>278.959991</td>\n",
       "      <td>286.549988</td>\n",
       "      <td>20777900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>285.359985</td>\n",
       "      <td>291.779999</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>287.519989</td>\n",
       "      <td>17361600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>286.250000</td>\n",
       "      <td>286.649994</td>\n",
       "      <td>281.070007</td>\n",
       "      <td>281.850006</td>\n",
       "      <td>12921700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>280.299988</td>\n",
       "      <td>283.459991</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>279.700012</td>\n",
       "      <td>10880300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>279.190002</td>\n",
       "      <td>288.489990</td>\n",
       "      <td>278.200012</td>\n",
       "      <td>285.579987</td>\n",
       "      <td>12995300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2153 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close     Volume  \\\n",
       "Date                                                                    \n",
       "2012-05-18   42.049999   45.000000   38.000000   38.230000  573576400   \n",
       "2012-05-21   36.529999   36.660000   33.000000   34.029999  168192700   \n",
       "2012-05-22   32.610001   33.590000   30.940001   31.000000  101786600   \n",
       "2012-05-23   31.370001   32.500000   31.360001   32.000000   73600000   \n",
       "2012-05-24   32.950001   33.209999   31.770000   33.029999   50237200   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2020-12-01  279.160004  289.299988  278.959991  286.549988   20777900   \n",
       "2020-12-02  285.359985  291.779999  280.829987  287.519989   17361600   \n",
       "2020-12-03  286.250000  286.649994  281.070007  281.850006   12921700   \n",
       "2020-12-04  280.299988  283.459991  279.299988  279.700012   10880300   \n",
       "2020-12-07  279.190002  288.489990  278.200012  285.579987   12995300   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2012-05-18          0             0  \n",
       "2012-05-21          0             0  \n",
       "2012-05-22          0             0  \n",
       "2012-05-23          0             0  \n",
       "2012-05-24          0             0  \n",
       "...               ...           ...  \n",
       "2020-12-01          0             0  \n",
       "2020-12-02          0             0  \n",
       "2020-12-03          0             0  \n",
       "2020-12-04          0             0  \n",
       "2020-12-07          0             0  \n",
       "\n",
       "[2153 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that uses TimeseriesGenerator class to generate the training set with dividends info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(data, value_num):\n",
    "    close = data['Close']\n",
    "    dividends = data['Dividends']\n",
    "    tsg = TimeseriesGenerator(close, close,\n",
    "                              length=value_num,\n",
    "                              batch_size=len(close))\n",
    "    global_index = value_num\n",
    "    i, t = tsg[0]\n",
    "    has_dividends = np.zeros(len(i))\n",
    "    for b_row in range(len(t)):\n",
    "        assert(abs(t[b_row] - close[global_index]) <= 0.001)\n",
    "        has_dividends[b_row] = dividends[global_index] > 0            \n",
    "        global_index += 1\n",
    "    return np.concatenate((i, np.transpose([has_dividends])),\n",
    "                           axis=1), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(history, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = history.min()\n",
    "normalized_h = (history - h_min) / (history.max() - h_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(normalized_h, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates a neural network with a specified number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(n+1,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs[:-1000]\n",
    "val_inputs = inputs[-1000:]\n",
    "train_targets = targets[:-1000]\n",
    "val_targets = targets[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_inputs(data, start, end, epochs):\n",
    "    models = {}\n",
    "    for inputs in range(start, end+1):\n",
    "        print('Using {} inputs'.format(inputs))\n",
    "        model_inputs, targets = generate_series(data, inputs)\n",
    "        \n",
    "        train_inputs = model_inputs[:-1000]\n",
    "        val_inputs = model_inputs[-1000:]\n",
    "        train_targets = targets[:-1000]\n",
    "        val_targets = targets[-1000:]\n",
    "        \n",
    "        m = create_model(inputs)\n",
    "        print('Training')\n",
    "        m.compile(optimizer='adam', loss='mse', metrics='accuracy') \n",
    "        h = m.fit(train_inputs, train_targets,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(val_inputs, val_targets))\n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[inputs] = model_info\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 8.6881e-04 - val_loss: 7.2902e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 5.3821e-05 - accuracy: 8.6881e-04 - val_loss: 4.1010e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.4061e-05 - accuracy: 8.6881e-04 - val_loss: 3.9850e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.1637e-05 - accuracy: 8.6881e-04 - val_loss: 4.5989e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.1018e-05 - accuracy: 8.6881e-04 - val_loss: 4.7906e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 2.9843e-05 - accuracy: 8.6881e-04 - val_loss: 5.2276e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.0641e-05 - accuracy: 8.6881e-04 - val_loss: 5.8846e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.0775e-05 - accuracy: 8.6881e-04 - val_loss: 4.1815e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 2.9372e-05 - accuracy: 8.6881e-04 - val_loss: 5.0973e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 2.9556e-05 - accuracy: 8.6881e-04 - val_loss: 4.4824e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 2.9813e-05 - accuracy: 8.6881e-04 - val_loss: 4.9251e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.0824e-05 - accuracy: 8.6881e-04 - val_loss: 4.2708e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 2.8671e-05 - accuracy: 8.6881e-04 - val_loss: 4.9257e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.9295e-05 - accuracy: 8.6881e-04 - val_loss: 4.8902e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.8725e-05 - accuracy: 8.6881e-04 - val_loss: 5.1206e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.0489e-05 - accuracy: 8.6881e-04 - val_loss: 5.2177e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.1097e-05 - accuracy: 8.6881e-04 - val_loss: 4.3522e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 2.8701e-05 - accuracy: 8.6881e-04 - val_loss: 4.5091e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 2.8340e-05 - accuracy: 8.6881e-04 - val_loss: 3.9675e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 2.9097e-05 - accuracy: 8.6881e-04 - val_loss: 4.1114e-04 - val_accuracy: 0.0010\n",
      "Using 3 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0194 - accuracy: 8.6957e-04 - val_loss: 0.0118 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7658e-04 - accuracy: 8.6957e-04 - val_loss: 0.0028 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 6.1508e-05 - accuracy: 8.6957e-04 - val_loss: 0.0035 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.4863e-05 - accuracy: 8.6957e-04 - val_loss: 0.0030 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5048e-05 - accuracy: 8.6957e-04 - val_loss: 0.0032 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.4632e-05 - accuracy: 8.6957e-04 - val_loss: 0.0033 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.0688e-05 - accuracy: 8.6957e-04 - val_loss: 0.0030 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.8881e-05 - accuracy: 8.6957e-04 - val_loss: 0.0030 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7233e-05 - accuracy: 8.6957e-04 - val_loss: 0.0032 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7575e-05 - accuracy: 8.6957e-04 - val_loss: 0.0030 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.4265e-05 - accuracy: 8.6957e-04 - val_loss: 0.0029 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7731e-05 - accuracy: 8.6957e-04 - val_loss: 0.0030 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4014e-05 - accuracy: 8.6957e-04 - val_loss: 0.0027 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.1691e-05 - accuracy: 8.6957e-04 - val_loss: 0.0031 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3610e-05 - accuracy: 8.6957e-04 - val_loss: 0.0026 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.7735e-05 - accuracy: 8.6957e-04 - val_loss: 0.0032 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.0062e-05 - accuracy: 8.6957e-04 - val_loss: 0.0029 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0137e-05 - accuracy: 8.6957e-04 - val_loss: 0.0031 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.0500e-05 - accuracy: 8.6957e-04 - val_loss: 0.0029 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8087e-05 - accuracy: 8.6957e-04 - val_loss: 0.0027 - val_accuracy: 0.0010\n",
      "Using 4 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0043 - accuracy: 8.7032e-04 - val_loss: 0.0035 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 7.5284e-05 - accuracy: 8.7032e-04 - val_loss: 7.7254e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2380e-05 - accuracy: 8.7032e-04 - val_loss: 7.2712e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.0500e-05 - accuracy: 8.7032e-04 - val_loss: 7.3817e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8785e-05 - accuracy: 8.7032e-04 - val_loss: 7.3340e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8035e-05 - accuracy: 8.7032e-04 - val_loss: 6.2911e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.6822e-05 - accuracy: 8.7032e-04 - val_loss: 7.7776e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 3.9732e-05 - accuracy: 8.7032e-04 - val_loss: 5.8090e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.6378e-05 - accuracy: 8.7032e-04 - val_loss: 6.7115e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.6224e-05 - accuracy: 8.7032e-04 - val_loss: 6.1662e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.6942e-05 - accuracy: 8.7032e-04 - val_loss: 5.7081e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.8548e-05 - accuracy: 8.7032e-04 - val_loss: 8.1124e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.4577e-05 - accuracy: 8.7032e-04 - val_loss: 6.6716e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 3.9020e-05 - accuracy: 8.7032e-04 - val_loss: 9.0012e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.3895e-05 - accuracy: 8.7032e-04 - val_loss: 6.0932e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.6050e-05 - accuracy: 8.7032e-04 - val_loss: 6.4268e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 3.3582e-05 - accuracy: 8.7032e-04 - val_loss: 6.2816e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.5973e-05 - accuracy: 8.7032e-04 - val_loss: 5.1196e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.5042e-05 - accuracy: 8.7032e-04 - val_loss: 6.3995e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.1640e-05 - accuracy: 8.7032e-04 - val_loss: 6.9237e-04 - val_accuracy: 0.0010\n",
      "Using 5 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 8.7108e-04 - val_loss: 0.0012 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 9.7952e-05 - accuracy: 8.7108e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.7727e-05 - accuracy: 8.7108e-04 - val_loss: 5.9958e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.9731e-05 - accuracy: 8.7108e-04 - val_loss: 4.5945e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8587e-05 - accuracy: 8.7108e-04 - val_loss: 5.1372e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.5051e-05 - accuracy: 8.7108e-04 - val_loss: 3.7560e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.3537e-05 - accuracy: 8.7108e-04 - val_loss: 3.5596e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 3.2571e-05 - accuracy: 8.7108e-04 - val_loss: 3.6909e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.1914e-05 - accuracy: 8.7108e-04 - val_loss: 3.9356e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.3611e-05 - accuracy: 8.7108e-04 - val_loss: 3.0401e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 3.4189e-05 - accuracy: 8.7108e-04 - val_loss: 4.4088e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.4259e-05 - accuracy: 8.7108e-04 - val_loss: 4.3111e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.3367e-05 - accuracy: 8.7108e-04 - val_loss: 2.6259e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.2388e-05 - accuracy: 8.7108e-04 - val_loss: 4.3691e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.0529e-05 - accuracy: 8.7108e-04 - val_loss: 3.6261e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 2.9812e-05 - accuracy: 8.7108e-04 - val_loss: 3.3177e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.2482e-05 - accuracy: 8.7108e-04 - val_loss: 2.7494e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.4182e-05 - accuracy: 8.7108e-04 - val_loss: 2.9177e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 2.9275e-05 - accuracy: 8.7108e-04 - val_loss: 2.9722e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 2.9962e-05 - accuracy: 8.7108e-04 - val_loss: 2.6732e-04 - val_accuracy: 0.0010\n",
      "Using 6 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0059 - accuracy: 8.7184e-04 - val_loss: 0.0069 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 1.1579e-04 - accuracy: 8.7184e-04 - val_loss: 9.8061e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 5.8820e-05 - accuracy: 8.7184e-04 - val_loss: 6.0553e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 5.3785e-05 - accuracy: 8.7184e-04 - val_loss: 5.9346e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 5.0331e-05 - accuracy: 8.7184e-04 - val_loss: 5.7299e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.2392e-05 - accuracy: 8.7184e-04 - val_loss: 5.0906e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.8195e-05 - accuracy: 8.7184e-04 - val_loss: 4.9397e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.5375e-05 - accuracy: 8.7184e-04 - val_loss: 4.5501e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.5224e-05 - accuracy: 8.7184e-04 - val_loss: 4.8806e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4242e-05 - accuracy: 8.7184e-04 - val_loss: 4.4392e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4140e-05 - accuracy: 8.7184e-04 - val_loss: 4.4718e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.2595e-05 - accuracy: 8.7184e-04 - val_loss: 4.2247e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2141e-05 - accuracy: 8.7184e-04 - val_loss: 4.1275e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.1326e-05 - accuracy: 8.7184e-04 - val_loss: 3.6858e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.0515e-05 - accuracy: 8.7184e-04 - val_loss: 3.4667e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.0542e-05 - accuracy: 8.7184e-04 - val_loss: 4.2580e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.9736e-05 - accuracy: 8.7184e-04 - val_loss: 3.3639e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.9396e-05 - accuracy: 8.7184e-04 - val_loss: 5.6864e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6906e-05 - accuracy: 8.7184e-04 - val_loss: 3.3289e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.2127e-05 - accuracy: 8.7184e-04 - val_loss: 3.9379e-04 - val_accuracy: 0.0010\n",
      "Using 7 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 8.7260e-04 - val_loss: 0.0094 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 1.6015e-04 - accuracy: 8.7260e-04 - val_loss: 0.0013 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 6.3302e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 5.9758e-05 - accuracy: 8.7260e-04 - val_loss: 0.0014 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.8096e-05 - accuracy: 8.7260e-04 - val_loss: 0.0012 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.7619e-05 - accuracy: 8.7260e-04 - val_loss: 0.0010 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.4944e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.4826e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.4318e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1605e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.1146e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.1396e-05 - accuracy: 8.7260e-04 - val_loss: 0.0011 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9277e-05 - accuracy: 8.7260e-04 - val_loss: 8.7104e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.8515e-05 - accuracy: 8.7260e-04 - val_loss: 9.6411e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.6971e-05 - accuracy: 8.7260e-04 - val_loss: 9.3743e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.9085e-05 - accuracy: 8.7260e-04 - val_loss: 0.0012 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.5510e-05 - accuracy: 8.7260e-04 - val_loss: 9.8413e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3287e-05 - accuracy: 8.7260e-04 - val_loss: 7.9741e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.3841e-05 - accuracy: 8.7260e-04 - val_loss: 8.7566e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.5712e-05 - accuracy: 8.7260e-04 - val_loss: 8.5028e-04 - val_accuracy: 0.0010\n",
      "Using 8 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 8.7336e-04 - val_loss: 8.8496e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 6.1846e-05 - accuracy: 8.7336e-04 - val_loss: 4.9008e-04 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.7077e-05 - accuracy: 8.7336e-04 - val_loss: 3.6315e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.5632e-05 - accuracy: 8.7336e-04 - val_loss: 3.5456e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.6853e-05 - accuracy: 8.7336e-04 - val_loss: 3.8005e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3140e-05 - accuracy: 8.7336e-04 - val_loss: 3.3118e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1799e-05 - accuracy: 8.7336e-04 - val_loss: 3.2260e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 4.0809e-05 - accuracy: 8.7336e-04 - val_loss: 3.1581e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 4.2750e-05 - accuracy: 8.7336e-04 - val_loss: 3.1236e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.1247e-05 - accuracy: 8.7336e-04 - val_loss: 3.0580e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7703e-05 - accuracy: 8.7336e-04 - val_loss: 3.0649e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.9356e-05 - accuracy: 8.7336e-04 - val_loss: 3.1059e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.7406e-05 - accuracy: 8.7336e-04 - val_loss: 2.9867e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.8277e-05 - accuracy: 8.7336e-04 - val_loss: 3.0503e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.2292e-05 - accuracy: 8.7336e-04 - val_loss: 2.9871e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 4.2118e-05 - accuracy: 8.7336e-04 - val_loss: 2.9700e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.7694e-05 - accuracy: 8.7336e-04 - val_loss: 3.0686e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.9879e-05 - accuracy: 8.7336e-04 - val_loss: 3.2140e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1227e-05 - accuracy: 8.7336e-04 - val_loss: 2.9069e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0908e-05 - accuracy: 8.7336e-04 - val_loss: 2.9662e-04 - val_accuracy: 0.0010\n",
      "Using 9 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0052 - accuracy: 8.7413e-04 - val_loss: 6.9797e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.6631e-04 - accuracy: 8.7413e-04 - val_loss: 0.0012 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 6.3838e-05 - accuracy: 8.7413e-04 - val_loss: 6.3608e-04 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.2894e-05 - accuracy: 8.7413e-04 - val_loss: 7.7509e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.7854e-05 - accuracy: 8.7413e-04 - val_loss: 5.1075e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6202e-05 - accuracy: 8.7413e-04 - val_loss: 3.8745e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0973e-05 - accuracy: 8.7413e-04 - val_loss: 5.0151e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.1785e-05 - accuracy: 8.7413e-04 - val_loss: 5.3386e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 4.6252e-05 - accuracy: 8.7413e-04 - val_loss: 4.5773e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.4137e-05 - accuracy: 8.7413e-04 - val_loss: 5.0765e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 4.1570e-05 - accuracy: 8.7413e-04 - val_loss: 3.2396e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 4.0811e-05 - accuracy: 8.7413e-04 - val_loss: 4.1041e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 3.7097e-05 - accuracy: 8.7413e-04 - val_loss: 3.1763e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.7647e-05 - accuracy: 8.7413e-04 - val_loss: 3.8934e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 3.5672e-05 - accuracy: 8.7413e-04 - val_loss: 4.0189e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.0517e-05 - accuracy: 8.7413e-04 - val_loss: 4.3620e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 3.6279e-05 - accuracy: 8.7413e-04 - val_loss: 3.0378e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.8520e-05 - accuracy: 8.7413e-04 - val_loss: 4.3521e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.7704e-05 - accuracy: 8.7413e-04 - val_loss: 3.0567e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.5161e-05 - accuracy: 8.7413e-04 - val_loss: 4.0951e-04 - val_accuracy: 0.0010\n",
      "Using 10 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0054 - accuracy: 8.7489e-04 - val_loss: 7.1143e-04 - val_accuracy: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 1.6763e-04 - accuracy: 8.7489e-04 - val_loss: 0.0013 - val_accuracy: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 8.2390e-05 - accuracy: 8.7489e-04 - val_loss: 0.0010 - val_accuracy: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 7.1251e-05 - accuracy: 8.7489e-04 - val_loss: 8.4591e-04 - val_accuracy: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 5.9796e-05 - accuracy: 8.7489e-04 - val_loss: 6.5820e-04 - val_accuracy: 0.0010\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.3100e-05 - accuracy: 8.7489e-04 - val_loss: 6.5047e-04 - val_accuracy: 0.0010\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.1750e-05 - accuracy: 8.7489e-04 - val_loss: 7.2737e-04 - val_accuracy: 0.0010\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.8335e-05 - accuracy: 8.7489e-04 - val_loss: 6.7927e-04 - val_accuracy: 0.0010\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.1408e-05 - accuracy: 8.7489e-04 - val_loss: 4.8152e-04 - val_accuracy: 0.0010\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.0321e-05 - accuracy: 8.7489e-04 - val_loss: 5.4076e-04 - val_accuracy: 0.0010\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.0192e-05 - accuracy: 8.7489e-04 - val_loss: 5.3379e-04 - val_accuracy: 0.0010\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.8364e-05 - accuracy: 8.7489e-04 - val_loss: 7.9265e-04 - val_accuracy: 0.0010\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 5.2249e-05 - accuracy: 8.7489e-04 - val_loss: 8.1568e-04 - val_accuracy: 0.0010\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.7193e-05 - accuracy: 8.7489e-04 - val_loss: 7.1917e-04 - val_accuracy: 0.0010\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.9295e-05 - accuracy: 8.7489e-04 - val_loss: 7.1943e-04 - val_accuracy: 0.0010\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.1217e-05 - accuracy: 8.7489e-04 - val_loss: 5.5951e-04 - val_accuracy: 0.0010\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.3107e-05 - accuracy: 8.7489e-04 - val_loss: 5.1050e-04 - val_accuracy: 0.0010\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 4.4192e-05 - accuracy: 8.7489e-04 - val_loss: 7.1360e-04 - val_accuracy: 0.0010\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 4.6507e-05 - accuracy: 8.7489e-04 - val_loss: 5.4968e-04 - val_accuracy: 0.0010\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 3.9033e-05 - accuracy: 8.7489e-04 - val_loss: 4.2319e-04 - val_accuracy: 0.0010\n"
     ]
    }
   ],
   "source": [
    "trained_models = select_inputs(normalized_h, 2, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(trained_models[2]['model'].predict(val_targets))\n",
    "# model = trained_models[2]['model']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "for k, v in trained_models.items():\n",
    "    train_history = v['history']\n",
    "    loss = train_history['loss'][-1]\n",
    "    val_loss = train_history['val_loss'][-1]\n",
    "    model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'inputs': 2,\n",
       "  'loss': 2.909661088779103e-05,\n",
       "  'val_loss': 0.0004111400048714131},\n",
       " 3: {'inputs': 3,\n",
       "  'loss': 3.8087160646682605e-05,\n",
       "  'val_loss': 0.0026771011762320995},\n",
       " 4: {'inputs': 4,\n",
       "  'loss': 3.1640141969546676e-05,\n",
       "  'val_loss': 0.0006923748296685517},\n",
       " 5: {'inputs': 5,\n",
       "  'loss': 2.9961756808916107e-05,\n",
       "  'val_loss': 0.0002673214767128229},\n",
       " 6: {'inputs': 6,\n",
       "  'loss': 4.2127358028665185e-05,\n",
       "  'val_loss': 0.00039379281224682927},\n",
       " 7: {'inputs': 7,\n",
       "  'loss': 4.571227327687666e-05,\n",
       "  'val_loss': 0.0008502771961502731},\n",
       " 8: {'inputs': 8,\n",
       "  'loss': 4.090834045200609e-05,\n",
       "  'val_loss': 0.00029661523876711726},\n",
       " 9: {'inputs': 9,\n",
       "  'loss': 3.5161479900125414e-05,\n",
       "  'val_loss': 0.0004095053591299802},\n",
       " 10: {'inputs': 10,\n",
       "  'loss': 3.903335164068267e-05,\n",
       "  'val_loss': 0.00042318663327023387}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb71ae11f40>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 17.847659590524273\n",
      "3 18.496132367879746\n",
      "4 17.92814337384337\n",
      "5 17.806501603543335\n",
      "6 17.8426951708675\n",
      "7 17.97333187373365\n",
      "8 17.81488489248872\n",
      "9 17.847191787599257\n",
      "10 17.85110709468908\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "close_min = history['Close'].min()\n",
    "close_max = history['Close'].max()\n",
    "for k in model_stats:\n",
    "    e = ((close_max - close_min) * model_stats[k]['val_loss'] + close_min)\n",
    "    vals.append(e)\n",
    "    print(k, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
