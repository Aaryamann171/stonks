{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOOGLE STOCKS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google's Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGL -- Google's ticker\n",
    "google = yf.Ticker('GOOGL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = google.history(period='max', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>50.050049</td>\n",
       "      <td>52.082081</td>\n",
       "      <td>48.028027</td>\n",
       "      <td>50.220219</td>\n",
       "      <td>44659000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>50.555557</td>\n",
       "      <td>54.594593</td>\n",
       "      <td>50.300301</td>\n",
       "      <td>54.209209</td>\n",
       "      <td>22834300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>55.430431</td>\n",
       "      <td>56.796795</td>\n",
       "      <td>54.579578</td>\n",
       "      <td>54.754753</td>\n",
       "      <td>18256100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>55.675674</td>\n",
       "      <td>55.855854</td>\n",
       "      <td>51.836838</td>\n",
       "      <td>52.487488</td>\n",
       "      <td>15247300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>52.532532</td>\n",
       "      <td>54.054054</td>\n",
       "      <td>51.991993</td>\n",
       "      <td>53.053055</td>\n",
       "      <td>9188600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>1766.660034</td>\n",
       "      <td>1821.719971</td>\n",
       "      <td>1763.030029</td>\n",
       "      <td>1795.359985</td>\n",
       "      <td>1868100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>1795.359985</td>\n",
       "      <td>1832.739990</td>\n",
       "      <td>1785.170044</td>\n",
       "      <td>1824.969971</td>\n",
       "      <td>1471200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>1820.540039</td>\n",
       "      <td>1843.829956</td>\n",
       "      <td>1817.000000</td>\n",
       "      <td>1821.839966</td>\n",
       "      <td>1236400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>1820.219971</td>\n",
       "      <td>1829.500000</td>\n",
       "      <td>1813.589966</td>\n",
       "      <td>1823.760010</td>\n",
       "      <td>1027200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>1815.550049</td>\n",
       "      <td>1829.290039</td>\n",
       "      <td>1803.040039</td>\n",
       "      <td>1817.030029</td>\n",
       "      <td>1113800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4105 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Volume  \\\n",
       "Date                                                                       \n",
       "2004-08-19    50.050049    52.082081    48.028027    50.220219  44659000   \n",
       "2004-08-20    50.555557    54.594593    50.300301    54.209209  22834300   \n",
       "2004-08-23    55.430431    56.796795    54.579578    54.754753  18256100   \n",
       "2004-08-24    55.675674    55.855854    51.836838    52.487488  15247300   \n",
       "2004-08-25    52.532532    54.054054    51.991993    53.053055   9188600   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "2020-12-01  1766.660034  1821.719971  1763.030029  1795.359985   1868100   \n",
       "2020-12-02  1795.359985  1832.739990  1785.170044  1824.969971   1471200   \n",
       "2020-12-03  1820.540039  1843.829956  1817.000000  1821.839966   1236400   \n",
       "2020-12-04  1820.219971  1829.500000  1813.589966  1823.760010   1027200   \n",
       "2020-12-07  1815.550049  1829.290039  1803.040039  1817.030029   1113800   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2004-08-19          0           0.0  \n",
       "2004-08-20          0           0.0  \n",
       "2004-08-23          0           0.0  \n",
       "2004-08-24          0           0.0  \n",
       "2004-08-25          0           0.0  \n",
       "...               ...           ...  \n",
       "2020-12-01          0           0.0  \n",
       "2020-12-02          0           0.0  \n",
       "2020-12-03          0           0.0  \n",
       "2020-12-04          0           0.0  \n",
       "2020-12-07          0           0.0  \n",
       "\n",
       "[4105 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function that uses TimeseriesGenerator class to generate the training set with dividends info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(data, value_num):\n",
    "    close = data['Close']\n",
    "    dividends = data['Dividends']\n",
    "    tsg = TimeseriesGenerator(close, close,\n",
    "                              length=value_num,\n",
    "                              batch_size=len(close))\n",
    "    global_index = value_num\n",
    "    i, t = tsg[0]\n",
    "    has_dividends = np.zeros(len(i))\n",
    "    for b_row in range(len(t)):\n",
    "        assert(abs(t[b_row] - close[global_index]) <= 0.001)\n",
    "        has_dividends[b_row] = dividends[global_index] > 0            \n",
    "        global_index += 1\n",
    "    return np.concatenate((i, np.transpose([has_dividends])),\n",
    "                           axis=1), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(history, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing MinMax normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_min = history.min()\n",
    "normalized_h = (history - h_min) / (history.max() - h_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = generate_series(normalized_h, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creates a neural network with a specified number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(64, activation='relu', input_shape=(n+1,)))\n",
    "    m.add(layers.Dense(64, activation='relu'))\n",
    "    m.add(layers.Dense(1))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs[:-1000]\n",
    "val_inputs = inputs[-1000:]\n",
    "train_targets = targets[:-1000]\n",
    "val_targets = targets[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_inputs(data, start, end, epochs):\n",
    "    models = {}\n",
    "    for inputs in range(start, end+1):\n",
    "        print('Using {} inputs'.format(inputs))\n",
    "        model_inputs, targets = generate_series(data, inputs)\n",
    "        \n",
    "        train_inputs = model_inputs[:-1000]\n",
    "        val_inputs = model_inputs[-1000:]\n",
    "        train_targets = targets[:-1000]\n",
    "        val_targets = targets[-1000:]\n",
    "        \n",
    "        m = create_model(inputs)\n",
    "        print('Training')\n",
    "        m.compile(optimizer='adam', loss='mse') \n",
    "        h = m.fit(train_inputs, train_targets,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32,\n",
    "                  validation_data=(val_inputs, val_targets))\n",
    "        model_info = {'model': m, 'history': h.history}\n",
    "        models[inputs] = model_info\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 3.5136e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8512e-05 - val_loss: 3.9098e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7864e-05 - val_loss: 3.9405e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.8180e-05 - val_loss: 3.1225e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7382e-05 - val_loss: 2.7641e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8092e-05 - val_loss: 3.7645e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.7759e-05 - val_loss: 3.2431e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8571e-05 - val_loss: 3.0995e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6606e-05 - val_loss: 3.5015e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.7711e-05 - val_loss: 3.4313e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6497e-05 - val_loss: 3.3508e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.8419e-05 - val_loss: 3.4759e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6994e-05 - val_loss: 3.3409e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.6117e-05 - val_loss: 3.9548e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.7105e-05 - val_loss: 3.3538e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6365e-05 - val_loss: 3.1883e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6872e-05 - val_loss: 4.4182e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7147e-05 - val_loss: 2.8763e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.6412e-05 - val_loss: 2.6828e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.8739e-05 - val_loss: 4.0846e-04\n",
      "Using 3 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 2.8861e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.2605e-05 - val_loss: 3.1534e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0935e-05 - val_loss: 4.3937e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1577e-05 - val_loss: 4.7209e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1004e-05 - val_loss: 2.8361e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1326e-05 - val_loss: 5.0372e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0052e-05 - val_loss: 3.7466e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.9894e-05 - val_loss: 4.1543e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9121e-05 - val_loss: 3.8574e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.8536e-05 - val_loss: 5.5116e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8396e-05 - val_loss: 3.2482e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6301e-05 - val_loss: 2.5771e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6285e-05 - val_loss: 2.8677e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8325e-05 - val_loss: 2.4161e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6728e-05 - val_loss: 3.1056e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6139e-05 - val_loss: 4.7464e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6896e-05 - val_loss: 2.9697e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8419e-05 - val_loss: 2.8310e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6721e-05 - val_loss: 3.7096e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7492e-05 - val_loss: 5.0981e-04\n",
      "Using 4 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0028 - val_loss: 6.5892e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.4030e-05 - val_loss: 4.0483e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3123e-05 - val_loss: 4.7978e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2587e-05 - val_loss: 4.3232e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1600e-05 - val_loss: 3.6814e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1299e-05 - val_loss: 3.3481e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1252e-05 - val_loss: 3.3987e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0064e-05 - val_loss: 3.8115e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9254e-05 - val_loss: 3.2461e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9258e-05 - val_loss: 2.7448e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9001e-05 - val_loss: 4.0767e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.8819e-05 - val_loss: 3.6675e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8942e-05 - val_loss: 4.0053e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7087e-05 - val_loss: 2.5217e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.7399e-05 - val_loss: 4.5487e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.6197e-05 - val_loss: 5.4117e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6631e-05 - val_loss: 3.4442e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6397e-05 - val_loss: 3.7994e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7338e-05 - val_loss: 3.5145e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6163e-05 - val_loss: 3.0646e-04\n",
      "Using 5 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0010 - val_loss: 2.8957e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.1985e-05 - val_loss: 2.8424e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.1721e-05 - val_loss: 2.7178e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9614e-05 - val_loss: 3.0252e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.9390e-05 - val_loss: 2.4257e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.6768e-05 - val_loss: 2.3116e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5260e-05 - val_loss: 2.1714e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4658e-05 - val_loss: 2.1376e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3731e-05 - val_loss: 1.9843e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3247e-05 - val_loss: 2.4803e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0640e-05 - val_loss: 1.8591e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3050e-05 - val_loss: 1.8563e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 2.1245e-05 - val_loss: 1.7396e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9676e-05 - val_loss: 1.8294e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0815e-05 - val_loss: 1.7871e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9004e-05 - val_loss: 1.6448e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0236e-05 - val_loss: 1.7418e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0863e-05 - val_loss: 2.2196e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.8054e-05 - val_loss: 2.0179e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8909e-05 - val_loss: 1.5947e-04\n",
      "Using 6 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 4.7431e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.3275e-05 - val_loss: 3.9001e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 3.0597e-05 - val_loss: 3.1567e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.7890e-05 - val_loss: 2.7402e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 2.5478e-05 - val_loss: 3.2313e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3014e-05 - val_loss: 2.3089e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1994e-05 - val_loss: 2.9973e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0709e-05 - val_loss: 2.8502e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8856e-05 - val_loss: 2.9765e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8930e-05 - val_loss: 1.8995e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1752e-05 - val_loss: 2.1114e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8071e-05 - val_loss: 2.6164e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.8896e-05 - val_loss: 2.1877e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6997e-05 - val_loss: 1.7830e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3654e-05 - val_loss: 1.7841e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7996e-05 - val_loss: 1.9030e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9917e-05 - val_loss: 2.1798e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.6191e-05 - val_loss: 1.8526e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.7672e-05 - val_loss: 2.3502e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.5715e-05 - val_loss: 1.7662e-04\n",
      "Using 7 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 4.3700e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.7942e-05 - val_loss: 5.2122e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.3594e-05 - val_loss: 3.4451e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5436e-05 - val_loss: 3.3272e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3356e-05 - val_loss: 2.3421e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9274e-05 - val_loss: 3.3808e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1115e-05 - val_loss: 2.6782e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.8631e-05 - val_loss: 2.0210e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0068e-05 - val_loss: 3.1781e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9509e-05 - val_loss: 2.3807e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.8791e-05 - val_loss: 2.1377e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7156e-05 - val_loss: 2.4133e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.6678e-05 - val_loss: 2.3644e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7857e-05 - val_loss: 2.4930e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.9152e-05 - val_loss: 2.0783e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7685e-05 - val_loss: 3.1319e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8381e-05 - val_loss: 2.5236e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.6985e-05 - val_loss: 2.8751e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.9020e-05 - val_loss: 2.4424e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7873e-05 - val_loss: 2.5895e-04\n",
      "Using 8 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 4.0351e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.4229e-05 - val_loss: 3.7925e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.2029e-05 - val_loss: 3.3768e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.8238e-05 - val_loss: 2.3527e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.6167e-05 - val_loss: 2.4629e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3454e-05 - val_loss: 2.3065e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2482e-05 - val_loss: 1.9157e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.9575e-05 - val_loss: 2.3706e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.1062e-05 - val_loss: 1.7017e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9123e-05 - val_loss: 3.9385e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9340e-05 - val_loss: 1.6303e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.7886e-05 - val_loss: 2.1946e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.8367e-05 - val_loss: 1.7323e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9019e-05 - val_loss: 3.5731e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.6425e-05 - val_loss: 1.8766e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7325e-05 - val_loss: 2.2595e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.7079e-05 - val_loss: 2.2674e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.7018e-05 - val_loss: 1.4858e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.9989e-05 - val_loss: 1.8874e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6365e-05 - val_loss: 2.2762e-04\n",
      "Using 9 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0014 - val_loss: 5.0082e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.0631e-05 - val_loss: 3.8970e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.5755e-05 - val_loss: 4.1337e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.1298e-05 - val_loss: 3.3019e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.7580e-05 - val_loss: 3.1591e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5617e-05 - val_loss: 2.5968e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3285e-05 - val_loss: 2.3060e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5390e-05 - val_loss: 3.7080e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.3207e-05 - val_loss: 2.0105e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3119e-05 - val_loss: 3.5197e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.1790e-05 - val_loss: 2.0991e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2502e-05 - val_loss: 2.0260e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0595e-05 - val_loss: 2.1601e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9094e-05 - val_loss: 2.1601e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9269e-05 - val_loss: 2.9177e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.1378e-05 - val_loss: 1.7728e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9642e-05 - val_loss: 2.2330e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.7537e-05 - val_loss: 2.1541e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9281e-05 - val_loss: 1.7818e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9926e-05 - val_loss: 2.4865e-04\n",
      "Using 10 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0015 - val_loss: 5.5371e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.1947e-05 - val_loss: 5.0358e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.5349e-05 - val_loss: 3.2081e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.8350e-05 - val_loss: 2.4475e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9557e-05 - val_loss: 2.7448e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3652e-05 - val_loss: 2.6817e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3205e-05 - val_loss: 2.1402e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1700e-05 - val_loss: 1.9414e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.8307e-05 - val_loss: 1.9809e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1480e-05 - val_loss: 1.9690e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3533e-05 - val_loss: 2.2778e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3459e-05 - val_loss: 2.1031e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3648e-05 - val_loss: 2.5880e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0420e-05 - val_loss: 2.0310e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.8501e-05 - val_loss: 2.5579e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3768e-05 - val_loss: 2.1408e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2246e-05 - val_loss: 1.9705e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9820e-05 - val_loss: 2.0559e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1280e-05 - val_loss: 1.8855e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1187e-05 - val_loss: 1.9233e-04\n",
      "Using 11 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 5.6562e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.9793e-05 - val_loss: 5.6990e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 4.6903e-05 - val_loss: 5.5255e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.3120e-05 - val_loss: 5.8543e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 4.1419e-05 - val_loss: 4.2530e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.9187e-05 - val_loss: 4.2542e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.7259e-05 - val_loss: 4.5767e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.5401e-05 - val_loss: 3.6529e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0554e-05 - val_loss: 3.2072e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.0008e-05 - val_loss: 2.9196e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.2398e-05 - val_loss: 4.8084e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5651e-05 - val_loss: 3.4663e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9381e-05 - val_loss: 2.6314e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.8696e-05 - val_loss: 2.9942e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.6784e-05 - val_loss: 2.5272e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4748e-05 - val_loss: 3.4588e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.6519e-05 - val_loss: 2.9148e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2699e-05 - val_loss: 2.2219e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4646e-05 - val_loss: 2.0845e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.4203e-05 - val_loss: 2.1030e-04\n",
      "Using 12 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0017 - val_loss: 5.6704e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 5.2531e-05 - val_loss: 4.4506e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.9607e-05 - val_loss: 4.7229e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.1195e-05 - val_loss: 4.1441e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9125e-05 - val_loss: 2.4266e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.5055e-05 - val_loss: 3.5114e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.1749e-05 - val_loss: 2.0444e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.1593e-05 - val_loss: 1.9087e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1823e-05 - val_loss: 2.2182e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0955e-05 - val_loss: 1.8900e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0271e-05 - val_loss: 3.3529e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3060e-05 - val_loss: 3.0677e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.2274e-05 - val_loss: 2.3770e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 1.8043e-05 - val_loss: 1.6809e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0999e-05 - val_loss: 2.8549e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.9518e-05 - val_loss: 1.7547e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9771e-05 - val_loss: 2.2375e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.0605e-05 - val_loss: 1.6326e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.1382e-05 - val_loss: 2.2851e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2273e-05 - val_loss: 1.8263e-04\n",
      "Using 13 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2721e-04 - val_loss: 4.5631e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 4.3045e-05 - val_loss: 3.4136e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0685e-05 - val_loss: 2.3563e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.8320e-05 - val_loss: 2.1195e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3071e-05 - val_loss: 2.5494e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8253e-05 - val_loss: 2.3881e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3054e-05 - val_loss: 3.8984e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3235e-05 - val_loss: 1.8602e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.5525e-05 - val_loss: 1.9380e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.5724e-05 - val_loss: 1.7494e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3855e-05 - val_loss: 1.9664e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.1656e-05 - val_loss: 2.3343e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.5836e-05 - val_loss: 1.8409e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.2775e-05 - val_loss: 3.4166e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5728e-05 - val_loss: 2.0830e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2310e-05 - val_loss: 1.6237e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.8563e-05 - val_loss: 2.8240e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.2425e-05 - val_loss: 2.0888e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 1.9944e-05 - val_loss: 1.7279e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.0642e-05 - val_loss: 1.7437e-04\n",
      "Using 14 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0030 - val_loss: 8.1628e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 5.7866e-05 - val_loss: 5.9947e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 4.7892e-05 - val_loss: 6.7736e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.4035e-05 - val_loss: 3.7520e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8489e-05 - val_loss: 2.8823e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5137e-05 - val_loss: 4.6277e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3160e-05 - val_loss: 3.4937e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1473e-05 - val_loss: 2.8885e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1517e-05 - val_loss: 3.0863e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0851e-05 - val_loss: 2.7040e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.1398e-05 - val_loss: 3.1648e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3636e-05 - val_loss: 6.3701e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.2215e-05 - val_loss: 2.7960e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.4560e-05 - val_loss: 4.2107e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.4935e-05 - val_loss: 3.1168e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9946e-05 - val_loss: 4.3180e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 1.9377e-05 - val_loss: 2.9069e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0618e-05 - val_loss: 2.6801e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.2813e-05 - val_loss: 3.0644e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 1.9656e-05 - val_loss: 3.6948e-04\n",
      "Using 15 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 4.8709e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.9263e-05 - val_loss: 3.1836e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.2135e-05 - val_loss: 3.3757e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.1954e-05 - val_loss: 2.9830e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.7955e-05 - val_loss: 2.6285e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.6937e-05 - val_loss: 3.1061e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5953e-05 - val_loss: 2.9029e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5307e-05 - val_loss: 2.7336e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.6043e-05 - val_loss: 2.4111e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.8091e-05 - val_loss: 4.1130e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.7169e-05 - val_loss: 2.3762e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.5659e-05 - val_loss: 2.3133e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.6154e-05 - val_loss: 2.3731e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3842e-05 - val_loss: 2.8851e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.3924e-05 - val_loss: 2.3354e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4669e-05 - val_loss: 2.5600e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.4533e-05 - val_loss: 2.1395e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.6105e-05 - val_loss: 2.6928e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.2192e-05 - val_loss: 2.1830e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3488e-05 - val_loss: 2.6576e-04\n",
      "Using 16 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0115 - val_loss: 0.0010\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 6.8533e-05 - val_loss: 6.1385e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.9960e-05 - val_loss: 4.7993e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.7234e-05 - val_loss: 4.5214e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.9151e-05 - val_loss: 4.1516e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.6549e-05 - val_loss: 4.3495e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.6484e-05 - val_loss: 3.8341e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.3123e-05 - val_loss: 3.1364e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.0219e-05 - val_loss: 4.8822e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.8168e-05 - val_loss: 3.2488e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.6108e-05 - val_loss: 3.1732e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.2034e-05 - val_loss: 2.5535e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.4086e-05 - val_loss: 4.0526e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.6560e-05 - val_loss: 2.3892e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.7280e-05 - val_loss: 3.8900e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3522e-05 - val_loss: 3.2392e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.3957e-05 - val_loss: 2.2491e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3850e-05 - val_loss: 2.3718e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 2.3177e-05 - val_loss: 2.1341e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0771e-05 - val_loss: 2.3040e-04\n",
      "Using 17 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 0.0052 - val_loss: 7.1731e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 6.0857e-05 - val_loss: 7.2427e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 5.2385e-05 - val_loss: 4.9697e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.3578e-05 - val_loss: 4.2960e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.0177e-05 - val_loss: 3.7449e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.8887e-05 - val_loss: 3.9320e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.5018e-05 - val_loss: 4.1495e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.5246e-05 - val_loss: 3.2402e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.7092e-05 - val_loss: 4.7372e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0852e-05 - val_loss: 3.3973e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8639e-05 - val_loss: 3.2716e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8751e-05 - val_loss: 3.0059e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.7927e-05 - val_loss: 2.9675e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.9135e-05 - val_loss: 2.4560e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.6302e-05 - val_loss: 5.4436e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.8160e-05 - val_loss: 2.4990e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.6583e-05 - val_loss: 2.3352e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5547e-05 - val_loss: 3.5814e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.6002e-05 - val_loss: 2.5587e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8334e-05 - val_loss: 3.0366e-04\n",
      "Using 18 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 6.2726e-04 - val_loss: 7.8888e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 6.0443e-05 - val_loss: 5.8783e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 5.1295e-05 - val_loss: 3.9605e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.6138e-05 - val_loss: 3.4865e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 4.0939e-05 - val_loss: 2.9872e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.3200e-05 - val_loss: 2.7337e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.3870e-05 - val_loss: 3.4753e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.8141e-05 - val_loss: 3.1242e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.1526e-05 - val_loss: 2.2858e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.6646e-05 - val_loss: 2.6712e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.9853e-05 - val_loss: 2.1830e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.7403e-05 - val_loss: 2.3344e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.2900e-05 - val_loss: 4.7556e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.8808e-05 - val_loss: 2.2083e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.8590e-05 - val_loss: 2.0366e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.1494e-05 - val_loss: 4.7060e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.6144e-05 - val_loss: 2.0590e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.5411e-05 - val_loss: 4.6814e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.6326e-05 - val_loss: 1.9895e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5096e-05 - val_loss: 1.9596e-04\n",
      "Using 19 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 7.1688e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.4857e-05 - val_loss: 3.9175e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 4.1252e-05 - val_loss: 4.1541e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.8332e-05 - val_loss: 5.9610e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 4.0740e-05 - val_loss: 3.3145e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.3900e-05 - val_loss: 3.0701e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.9896e-05 - val_loss: 2.9740e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.4368e-05 - val_loss: 5.7883e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.6103e-05 - val_loss: 6.2567e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.1630e-05 - val_loss: 3.7896e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.9962e-05 - val_loss: 2.7961e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.1683e-05 - val_loss: 2.5792e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.9612e-05 - val_loss: 2.5480e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.3106e-05 - val_loss: 2.4559e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9110e-05 - val_loss: 2.8169e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0163e-05 - val_loss: 2.2246e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 3.0928e-05 - val_loss: 3.9332e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0455e-05 - val_loss: 2.6259e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.1588e-05 - val_loss: 2.2323e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5689e-05 - val_loss: 2.8403e-04\n",
      "Using 20 inputs\n",
      "Training\n",
      "Epoch 1/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 6.9291e-04 - val_loss: 5.3686e-04\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 4.3699e-05 - val_loss: 3.8294e-04\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 4.0089e-05 - val_loss: 3.2059e-04\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.6278e-05 - val_loss: 2.9761e-04\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0967e-05 - val_loss: 2.9396e-04\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 3.1881e-05 - val_loss: 2.9044e-04\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 3.2282e-05 - val_loss: 7.0986e-04\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.1586e-05 - val_loss: 2.5429e-04\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 3.0795e-05 - val_loss: 2.7040e-04\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.7401e-05 - val_loss: 2.3364e-04\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.6916e-05 - val_loss: 2.2633e-04\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.2221e-05 - val_loss: 2.5442e-04\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 4.0327e-05 - val_loss: 2.6832e-04\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 5ms/step - loss: 2.9749e-05 - val_loss: 2.1130e-04\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.7692e-05 - val_loss: 1.9429e-04\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5405e-05 - val_loss: 2.4198e-04\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.5654e-05 - val_loss: 1.8903e-04\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.5362e-05 - val_loss: 1.8406e-04\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 2.5127e-05 - val_loss: 2.3120e-04\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 2.3276e-05 - val_loss: 1.7892e-04\n"
     ]
    }
   ],
   "source": [
    "trained_models = select_inputs(normalized_h, 2, 20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "for k, v in trained_models.items():\n",
    "    train_history = v['history']\n",
    "    loss = train_history['loss'][-1]\n",
    "    val_loss = train_history['val_loss'][-1]\n",
    "    model_stats[k] = {'inputs': k, 'loss': loss, 'val_loss': val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'inputs': 2,\n",
       "  'loss': 1.873864675872028e-05,\n",
       "  'val_loss': 0.00040846155025064945},\n",
       " 3: {'inputs': 3,\n",
       "  'loss': 1.749165130604524e-05,\n",
       "  'val_loss': 0.0005098145338706672},\n",
       " 4: {'inputs': 4,\n",
       "  'loss': 1.616348345123697e-05,\n",
       "  'val_loss': 0.0003064560587517917},\n",
       " 5: {'inputs': 5,\n",
       "  'loss': 1.8908987840404734e-05,\n",
       "  'val_loss': 0.00015947295469231904},\n",
       " 6: {'inputs': 6,\n",
       "  'loss': 1.5714951587142423e-05,\n",
       "  'val_loss': 0.000176623638253659},\n",
       " 7: {'inputs': 7,\n",
       "  'loss': 1.787310975487344e-05,\n",
       "  'val_loss': 0.0002589504001662135},\n",
       " 8: {'inputs': 8,\n",
       "  'loss': 1.636492925172206e-05,\n",
       "  'val_loss': 0.00022762120352126658},\n",
       " 9: {'inputs': 9,\n",
       "  'loss': 1.992569195863325e-05,\n",
       "  'val_loss': 0.00024864808074198663},\n",
       " 10: {'inputs': 10,\n",
       "  'loss': 2.118743213941343e-05,\n",
       "  'val_loss': 0.00019233192142564803},\n",
       " 11: {'inputs': 11,\n",
       "  'loss': 2.42032856476726e-05,\n",
       "  'val_loss': 0.00021029931667726487},\n",
       " 12: {'inputs': 12,\n",
       "  'loss': 2.2273285139817744e-05,\n",
       "  'val_loss': 0.00018263093079440296},\n",
       " 13: {'inputs': 13,\n",
       "  'loss': 2.06421591428807e-05,\n",
       "  'val_loss': 0.0001743661123327911},\n",
       " 14: {'inputs': 14,\n",
       "  'loss': 1.9655890355352312e-05,\n",
       "  'val_loss': 0.0003694843326229602},\n",
       " 15: {'inputs': 15,\n",
       "  'loss': 2.3488093574997038e-05,\n",
       "  'val_loss': 0.0002657616278156638},\n",
       " 16: {'inputs': 16,\n",
       "  'loss': 2.077122189803049e-05,\n",
       "  'val_loss': 0.00023040281666908413},\n",
       " 17: {'inputs': 17,\n",
       "  'loss': 2.8334448870737106e-05,\n",
       "  'val_loss': 0.00030365894781425595},\n",
       " 18: {'inputs': 18,\n",
       "  'loss': 2.5095896489801817e-05,\n",
       "  'val_loss': 0.00019596001948229969},\n",
       " 19: {'inputs': 19,\n",
       "  'loss': 2.568914533185307e-05,\n",
       "  'val_loss': 0.0002840347297023982},\n",
       " 20: {'inputs': 20,\n",
       "  'loss': 2.3276488718693145e-05,\n",
       "  'val_loss': 0.00017892404866870493}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52707705e0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = []\n",
    "indices = []\n",
    "for k, v in model_stats.items():\n",
    "    indices.append(k)\n",
    "    val_loss.append(v['val_loss'])\n",
    "plt.plot(indices, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50.78003820949513\n",
      "3 50.959931132003966\n",
      "4 50.59898714101869\n",
      "5 50.33810463707772\n",
      "6 50.36854564116735\n",
      "7 50.51466863895361\n",
      "8 50.459061980491114\n",
      "9 50.496382898527926\n",
      "10 50.396426507289654\n",
      "11 50.42831710514124\n",
      "12 50.37920807430865\n",
      "13 50.364538724734906\n",
      "14 50.7108569645049\n",
      "15 50.52675798851165\n",
      "16 50.463999107160475\n",
      "17 50.594022507091175\n",
      "18 50.40286607265071\n",
      "19 50.55919118963013\n",
      "20 50.37262867392822\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "close_min = history['Close'].min()\n",
    "close_max = history['Close'].max()\n",
    "for k in model_stats:\n",
    "    e = ((close_max - close_min) * model_stats[k]['val_loss'] + close_min)\n",
    "    vals.append(e)\n",
    "    print(k, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2-10 inputs, 20 epochs**\n",
    "2 54.58207831032934 <br>\n",
    "3 50.86012653433954 <br>\n",
    "4 50.581569596814134 <br>\n",
    "5 50.957972201969014 <br>\n",
    "6 50.31649620066624 <br>\n",
    "7 50.3439040710904 <br>\n",
    "8 51.20808844255482 <br>\n",
    "9 51.724607286824885 <br>\n",
    "10 50.38386250901514 <br>\n",
    "\n",
    "### **2-10 inputs, 40 epochs**\n",
    "2 52.841764082094016 <br>\n",
    "3 50.69386409104074 <br>\n",
    "4 50.668197158859236 <br>\n",
    "5 50.67976312148847 <br>\n",
    "6 50.40840350325806 <br>\n",
    "7 50.47386411392792 <br>\n",
    "8 50.61482935875455 <br>\n",
    "9 50.42015251183895 <br>\n",
    "10 50.38706887383594 <br>\n",
    "\n",
    "### **2-20 inputs, 20 epochs**\n",
    "2 50.78003820949513 <br>\n",
    "3 50.959931132003966 <br>\n",
    "4 50.59898714101869 <br>\n",
    "5 50.33810463707772 <br>\n",
    "6 50.36854564116735 <br>\n",
    "7 50.51466863895361 <br>\n",
    "8 50.459061980491114 <br>\n",
    "9 50.496382898527926 <br>\n",
    "10 50.396426507289654 <br>\n",
    "11 50.42831710514124 <br>\n",
    "12 50.37920807430865 <br>\n",
    "13 50.364538724734906 <br>\n",
    "14 50.7108569645049 <br>\n",
    "15 50.52675798851165 <br>\n",
    "16 50.463999107160475 <br>\n",
    "17 50.594022507091175 <br>\n",
    "18 50.40286607265071 <br>\n",
    "19 50.55919118963013 <br>\n",
    "20 50.37262867392822 <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
